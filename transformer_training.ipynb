{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loging to Sagemaker ECR with Deep Learning Containers\n",
    "!aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-2.amazonaws.com\n",
    "# loging to your private ECR\n",
    "!aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 553020858742.dkr.ecr.us-east-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize -l docker Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon    235kB\n",
      "Step 1/10 : FROM 763104351884.dkr.ecr.us-east-2.amazonaws.com/pytorch-training:1.5.0-gpu-py36-cu101-ubuntu16.04\n",
      " ---> 47cd15520b75\n",
      "Step 2/10 : LABEL author=\"vadimd@amazon.com\"\n",
      " ---> Using cache\n",
      " ---> 9b087555bcfc\n",
      "Step 3/10 : WORKDIR /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> c61703f87573\n",
      "Step 4/10 : RUN git clone https://github.com/huggingface/transformers\n",
      " ---> Using cache\n",
      " ---> ba58d750198b\n",
      "Step 5/10 : RUN cd transformers/ &&     python3 -m pip install --no-cache-dir .\n",
      " ---> Using cache\n",
      " ---> b3f2b386ac2a\n",
      "Step 6/10 : COPY container_training /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> fd7a41991831\n",
      "Step 7/10 : ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
      " ---> Using cache\n",
      " ---> b7ecc83b8913\n",
      "Step 8/10 : ENV SAGEMAKER_PROGRAM train_transformer.py\n",
      " ---> Using cache\n",
      " ---> e4eb92fe63fd\n",
      "Step 9/10 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> e5fe5e635b1b\n",
      "Step 10/10 : ENTRYPOINT [\"bash\", \"-m\", \"start_with_right_hostname.sh\"]\n",
      " ---> Using cache\n",
      " ---> 3db1c21c4543\n",
      "Successfully built 3db1c21c4543\n",
      "Successfully tagged hf-transformers-sm:latest\n",
      "The push refers to repository [553020858742.dkr.ecr.us-east-2.amazonaws.com/hf-transformers-sm]\n",
      "\n",
      "\u001b[1B31039174: Preparing \n",
      "\u001b[1B58b3c9b1: Preparing \n",
      "\u001b[1B93d4b5e7: Preparing \n",
      "\u001b[1Bcfa47cfc: Preparing \n",
      "\u001b[1Bdc6eccf1: Preparing \n",
      "\u001b[1Be8cb8ead: Preparing \n",
      "\u001b[1B18b6f784: Preparing \n",
      "\u001b[1Bbe96fc82: Preparing \n",
      "\u001b[1B2b332e53: Preparing \n",
      "\u001b[1Bc6e1c93f: Preparing \n",
      "\u001b[1B8af0cced: Preparing \n",
      "\u001b[1Ba1e058e6: Preparing \n",
      "\u001b[1Ba7e2d141: Preparing \n",
      "\u001b[1B891256c7: Preparing \n",
      "\u001b[1B4275da12: Preparing \n",
      "\u001b[1B8601ef26: Preparing \n",
      "\u001b[1B03245374: Preparing \n",
      "\u001b[1Be3aaa392: Preparing \n",
      "\u001b[1B09ca2db2: Preparing \n",
      "\u001b[1B3589d5b4: Preparing \n",
      "\u001b[1B3141886c: Preparing \n",
      "\u001b[1Bab783b62: Preparing \n",
      "\u001b[1B20da503d: Preparing \n",
      "\u001b[1Bdadd4466: Preparing \n",
      "\u001b[1B74e50f52: Preparing \n",
      "\u001b[21B8cb8ead: Waiting g \n",
      "\u001b[1B74ebe255: Preparing \n",
      "\u001b[22B8b6f784: Waiting g \n",
      "\u001b[1B42719515: Preparing \n",
      "\u001b[23Be96fc82: Waiting g \n",
      "\u001b[23Bb332e53: Waiting g \n",
      "\u001b[1Bb9b0fb21: Layer already exists \u001b[27A\u001b[2K\u001b[20A\u001b[2K\u001b[18A\u001b[2K\u001b[9A\u001b[2K\u001b[1A\u001b[2Klatest: digest: sha256:bfdfc0869f618400c9fc2242705ec7bf934e026932db7e58d09d6c072cb9bfa2 size: 7045\n"
     ]
    }
   ],
   "source": [
    "! ./build_and_push.sh hf-transformers-sm latest Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sagemaker.LocalSession() # can use LocalSession() to run container locally\n",
    "# sess = sagemaker.Session()\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "region = \"us-east-2\"\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "prefix_input = 'transformer-input'\n",
    "prefix_output = 'transformer-ouput'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = \"hf-transformers-sm\" # your container name\n",
    "tag = \"latest\"\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:{}'.format(account, region, container, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder\n",
    "lng_model_metrics=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lng_model_hp = {\n",
    "    \n",
    "    \"nlp-problem\":\"language-modeling\",\n",
    "    \"dataset\" : \"wiki\",\n",
    "    \"do_train\" : \"true\", # whether to train your model\n",
    "    \"do_eval\" : \"true\",  # whether to run evaluation\n",
    "    \"fp16\" : \"true\",     # using mixed precision\n",
    "\n",
    "    #### Algo hyperparameters\n",
    "    \"model_type\" : \"gpt2\",\n",
    "    \"model_name_or_path\" : \"gpt2\",\n",
    "    \"per_gpu_train_batch_size\" : \"2\",\n",
    "    \"per_gpu_eval_batch_size\" : \"2\",\n",
    "    \"gradient_accumulation_steps\" : \"2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpc2680p5v_algo-1-edk7g_1 ... \n",
      "\u001b[1BAttaching to tmpc2680p5v_algo-1-edk7g_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:00,087 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:00,089 sagemaker-containers INFO     Failed to parse hyperparameter nlp-problem value language-modeling to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:00,089 sagemaker-containers INFO     Failed to parse hyperparameter dataset value wiki to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:00,089 sagemaker-containers INFO     Failed to parse hyperparameter model_type value gpt2 to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:00,089 sagemaker-containers INFO     Failed to parse hyperparameter model_name_or_path value gpt2 to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:00,166 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:00,169 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:00,357 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Generating setup.py\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:00,357 sagemaker-containers INFO     Generating setup.cfg\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:00,358 sagemaker-containers INFO     Generating MANIFEST.in\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:00,358 sagemaker-containers INFO     Installing module with the following command:\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m /opt/conda/bin/python -m pip install . \n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Processing /tmp/tmpx7wr6pgl/module_dir\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Building wheels for collected packages: default-user-module-name\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m   Building wheel for default-user-module-name (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m \u001b[?25h  Created wheel for default-user-module-name: filename=default_user_module_name-1.0.0-py2.py3-none-any.whl size=31129688 sha256=93b039229bbcb4635a17bfb3c3fafdc1d5ec062411d94b0eaf9f0dc7e0cd8021\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m   Stored in directory: /tmp/pip-ephem-wheel-cache-mk7sk1ei/wheels/a2/fa/10/d360efaeaf62e927004bf234004057f76d10bad854d0992ea9\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Successfully built default-user-module-name\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Installing collected packages: default-user-module-name\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Successfully installed default-user-module-name-1.0.0\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m \u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:06,516 sagemaker-containers INFO     Failed to parse hyperparameter nlp-problem value language-modeling to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:06,516 sagemaker-containers INFO     Failed to parse hyperparameter dataset value wiki to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:06,516 sagemaker-containers INFO     Failed to parse hyperparameter model_type value gpt2 to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:06,516 sagemaker-containers INFO     Failed to parse hyperparameter model_name_or_path value gpt2 to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:06,530 sagemaker-containers INFO     Failed to parse hyperparameter nlp-problem value language-modeling to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:06,530 sagemaker-containers INFO     Failed to parse hyperparameter dataset value wiki to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:06,530 sagemaker-containers INFO     Failed to parse hyperparameter model_type value gpt2 to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:06,530 sagemaker-containers INFO     Failed to parse hyperparameter model_name_or_path value gpt2 to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:06,610 sagemaker-containers INFO     Failed to parse hyperparameter nlp-problem value language-modeling to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:06,610 sagemaker-containers INFO     Failed to parse hyperparameter dataset value wiki to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:06,610 sagemaker-containers INFO     Failed to parse hyperparameter model_type value gpt2 to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:06,611 sagemaker-containers INFO     Failed to parse hyperparameter model_name_or_path value gpt2 to Json.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Returning the value itself\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m 2020-05-20 16:33:06,690 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m \n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m \n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"test\": \"/opt/ml/input/data/test\"\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"current_host\": \"algo-1-edk7g\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"algo-1-edk7g\"\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"nlp-problem\": \"language-modeling\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"dataset\": \"wiki\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"do_train\": true,\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"do_eval\": true,\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"fp16\": true,\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"model_type\": \"gpt2\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"model_name_or_path\": \"gpt2\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"per_gpu_train_batch_size\": 2,\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"per_gpu_eval_batch_size\": 2,\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"gradient_accumulation_steps\": 2\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"train\": {\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         },\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"test\": {\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"job_name\": \"hf-transformers-batch2-fp16-v2\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"master_hostname\": \"algo-1-edk7g\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"module_dir\": \"/opt/ml/code\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"module_name\": \"train_transformer\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"num_cpus\": 64,\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"num_gpus\": 8,\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"current_host\": \"algo-1-edk7g\",\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m             \"algo-1-edk7g\"\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m     \"user_entry_point\": \"train_transformer.py\"\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m \n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m \n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_HOSTS=[\"algo-1-edk7g\"]\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_HPS={\"dataset\":\"wiki\",\"do_eval\":true,\"do_train\":true,\"fp16\":true,\"gradient_accumulation_steps\":2,\"model_name_or_path\":\"gpt2\",\"model_type\":\"gpt2\",\"nlp-problem\":\"language-modeling\",\"per_gpu_eval_batch_size\":2,\"per_gpu_train_batch_size\":2}\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_USER_ENTRY_POINT=train_transformer.py\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-edk7g\",\"hosts\":[\"algo-1-edk7g\"]}\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_CHANNELS=[\"test\",\"train\"]\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_CURRENT_HOST=algo-1-edk7g\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_MODULE_NAME=train_transformer\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_NUM_CPUS=64\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_NUM_GPUS=8\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_MODULE_DIR=/opt/ml/code\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-edk7g\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-edk7g\"],\"hyperparameters\":{\"dataset\":\"wiki\",\"do_eval\":true,\"do_train\":true,\"fp16\":true,\"gradient_accumulation_steps\":2,\"model_name_or_path\":\"gpt2\",\"model_type\":\"gpt2\",\"nlp-problem\":\"language-modeling\",\"per_gpu_eval_batch_size\":2,\"per_gpu_train_batch_size\":2},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"hf-transformers-batch2-fp16-v2\",\"log_level\":20,\"master_hostname\":\"algo-1-edk7g\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/code\",\"module_name\":\"train_transformer\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-edk7g\",\"hosts\":[\"algo-1-edk7g\"]},\"user_entry_point\":\"train_transformer.py\"}\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_USER_ARGS=[\"--dataset\",\"wiki\",\"--do_eval\",\"True\",\"--do_train\",\"True\",\"--fp16\",\"True\",\"--gradient_accumulation_steps\",\"2\",\"--model_name_or_path\",\"gpt2\",\"--model_type\",\"gpt2\",\"--nlp-problem\",\"language-modeling\",\"--per_gpu_eval_batch_size\",\"2\",\"--per_gpu_train_batch_size\",\"2\"]\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_HP_NLP-PROBLEM=language-modeling\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_HP_DATASET=wiki\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_HP_DO_TRAIN=true\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_HP_DO_EVAL=true\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_HP_FP16=true\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_HP_MODEL_TYPE=gpt2\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_HP_MODEL_NAME_OR_PATH=gpt2\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_HP_PER_GPU_TRAIN_BATCH_SIZE=2\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_HP_PER_GPU_EVAL_BATCH_SIZE=2\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m SM_HP_GRADIENT_ACCUMULATION_STEPS=2\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m \n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m \n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m /opt/conda/bin/python train_transformer.py --dataset wiki --do_eval True --do_train True --fp16 True --gradient_accumulation_steps 2 --model_name_or_path gpt2 --model_type gpt2 --nlp-problem language-modeling --per_gpu_eval_batch_size 2 --per_gpu_train_batch_size 2\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m \n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m \n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Starting training...\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m ***** sys.args *****\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m ['', '--nnodes', '1', '--node_rank', '0', '--nproc_per_node', '8', '--master_addr', 'algo-1-edk7g', '--master_port', '55555', '/opt/ml/code/transformers/examples/language-modeling/run_language_modeling.py', '--do_eval', '--do_train', '--fp16', '--gradient_accumulation_steps', '2', '--model_name_or_path', 'gpt2', '--model_type', 'gpt2', '--per_gpu_eval_batch_size', '2', '--per_gpu_train_batch_size', '2', '--train_data_file', '/opt/ml/input/data/train/wiki.train.raw', '--eval_data_file', '/opt/ml/input/data/test/wiki.test.raw', '--output_dir', '/opt/ml/output/data']\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m *****************************************\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m *****************************************\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m \n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Defaults for this optimization level are:\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m enabled                : True\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m opt_level              : O1\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m cast_model_type        : None\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m patch_torch_functions  : True\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m keep_batchnorm_fp32    : None\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m master_weights         : None\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m loss_scale             : dynamic\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m Processing user overrides (additional kwargs that are not None)...\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m After processing overrides, optimization options are:\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m enabled                : True\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m opt_level              : O1\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m cast_model_type        : None\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m patch_torch_functions  : True\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m keep_batchnorm_fp32    : None\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m master_weights         : None\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m loss_scale             : dynamic\n",
      "\u001b[36malgo-1-edk7g_1  |\u001b[0m NCCL version 2.4.8+cuda10.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-7ca77b3b7342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m              \"test\":\"s3://vadimd-nlp-datasets/wikitext-2-raw/wiki.test.raw\"},\n\u001b[1;32m     14\u001b[0m              \u001b[0mjob_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"hf-transformers-batch2-fp16-v2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m              \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m            ) \n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0mtrain_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"enable_sagemaker_metrics\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_sagemaker_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image, algorithm_arn, encrypt_inter_container_traffic, train_use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     def process(\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;31m# _stream_output() doesn't have the command line. We will handle the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lng_est = sagemaker.estimator.Estimator(image,\n",
    "                                   role=role,\n",
    "                                   train_instance_count=1, \n",
    "#                                    train_instance_type='ml.p3.16xlarge',\n",
    "                                   train_instance_type=\"local_gpu\", # use local_gpu for quick troubleshooting\n",
    "#                                    train_volume_size=100,\n",
    "                                   output_path=\"s3://{}/{}\".format(sess.default_bucket(), prefix_output),\n",
    "                                   metric_definitions = lng_model_metrics,\n",
    "                                   hyperparameters = lng_model_hp, \n",
    "                                   sagemaker_session=sess)\n",
    "\n",
    "lng_est.fit({\"train\":\"s3://vadimd-nlp-datasets/wikitext-2-raw/wiki.train.raw\", \n",
    "             \"test\":\"s3://vadimd-nlp-datasets/wikitext-2-raw/wiki.test.raw\"},\n",
    "             job_name = \"hf-transformers-batch2-fp16-v2\",\n",
    "             wait=False\n",
    "           ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train for GLUE benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download script for GLUE data download\n",
    "!wget https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python download_glue_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./upload_data_to_s3.sh vadimd-nlp-datasets glue glue_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cls_hp = {\n",
    "    \"nlp-problem\" : \"text-classification\",\n",
    "    \"do_train\" : \"true\", # whether to train your model\n",
    "    \"do_eval\" : \"true\",  # whether to run evaluation\n",
    "    \n",
    "    #### Algo hyperparameters\n",
    "    \"task_name\" : \"MRPC\", \n",
    "    \"model_type\" : \"bert\",\n",
    "    \"model_name_or_path\" : \"bert-base-cased\", # provide only model name\n",
    "    \"max_seq_length\" : 128,\n",
    "    \"per_gpu_train_batch_size\" : 32,\n",
    "    \"learning_rate\" : 2e-5,\n",
    "    \"num_train_epochs\" : 3.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder\n",
    "text_cls_metrics=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_est = sagemaker.estimator.Estimator(image,\n",
    "                                   role=role,\n",
    "                                   train_instance_count=1, \n",
    "                                   train_instance_type='ml.p3.2xlarge',\n",
    "#                                   train_instance_type=\"local_gpu\", # use local_gpu for quick troubleshooting\n",
    "#                                   train_volume_size=100,\n",
    "                                   output_path=\"s3://{}/{}\".format(sess.default_bucket(), prefix_output),\n",
    "                                   metric_definitions = text_cls_metrics,\n",
    "                                   hyperparameters = text_cls_hp, \n",
    "                                   sagemaker_session=sess)\n",
    "\n",
    "# TODO: prepare data channels\n",
    "cls_est.fit({\"train\":\"s3://vadimd-nlp-datasets/glue/MRPC\"},\n",
    "            job_name = \"hf-transformers-glue-v2\",\n",
    "            wait=False) \n",
    "\n",
    "#  s3://vadimd-nlp-datasets/glue/MNLI/train.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
